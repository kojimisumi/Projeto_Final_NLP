{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final do Turing de NLP para os Trainees - Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa parte do projeto se trata de fazermos um pré-processamento de uma base de dados do IMDB que contêm reviews de filmes e o sentimento desse review (sendo positivo ou negativo) e depois aplicarmos um modelo de predição baseado no BoW (\"bag of words\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports para o nosso código\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o dataset \n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-) Pré-processamentos\n",
    "* Criar uma função que realiza todos os pré-processamentos\n",
    "    * Remover tags html com BeautifulSoup\n",
    "    * Selecionar apenas letras com regex\n",
    "    * Transformar o texto para letras minúsculas\n",
    "    * Remover stopwords\n",
    "    * Stemização/Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(texto):\n",
    "    soup = BeautifulSoup(texto, \"html.parser\")\n",
    "    texto_tratado = soup.get_text(separator=\" \")\n",
    "    return texto_tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_review(review):\n",
    "    \n",
    "    review_2 = []\n",
    "    for word in review:\n",
    "        word_ = str(word)\n",
    "        word_ = word_.lower() \n",
    "        review_2.append(word_)\n",
    "\n",
    "    return review_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tira_stopwords(review):\n",
    "    \n",
    "    filtered_sentence = [] \n",
    "    for word in review:\n",
    "        if word not in stop_words: \n",
    "            filtered_sentence.append(word) \n",
    "            \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando o stemmizador\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamentos(review):\n",
    "    #primeiro vamos retirar as tags de html\n",
    "    review = strip_html_tags(review)\n",
    "    \n",
    "    #selecionamos as palavras sem os números\n",
    "    review = re.findall(r'[a-z,A-Z]\\w+',review)\n",
    "    \n",
    "    #transformar as palavras em lower case\n",
    "    review = trata_review(review)\n",
    "    \n",
    "    #agora vamos tirar os stopwords\n",
    "    review = tira_stopwords(review)\n",
    "    \n",
    "    #Stemização das palavras   \n",
    "    for i in range(len(review)):\n",
    "        review[i] = porter.stem(review[i])\n",
    "                                          \n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#aplicar para todo o dataframe os pré-processamentos\n",
    "df[\"review_tratado\"] = df[\"review\"].apply(lambda x: pre_processamentos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 -) Feature Extraction\n",
    "* A ideia é fazer um \"bag of words\" para podermos utilizar como feature para um modelo de predição de sentimento a partir dos reviews\n",
    "    * A partir disso monto um dataframe com essas features e coloco a coluna com o nosso \"target\"(sentimento) sendo 1 para positivo e 0 para negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar para texto já que o modelo CountVEctorizer recebe texto\n",
    "df[\"review_tratado\"] = df[\"review_tratado\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando o modelo e ajustando com os dados (coluna de \"review_tratado\")\n",
    "vec = CountVectorizer(max_features = 200)\n",
    "X = vec.fit_transform(df[\"review_tratado\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'although',\n",
       " 'alway',\n",
       " 'american',\n",
       " 'anoth',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'appear',\n",
       " 'around',\n",
       " 'audienc',\n",
       " 'away',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'beauti',\n",
       " 'becom',\n",
       " 'begin',\n",
       " 'believ',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'book',\n",
       " 'bore',\n",
       " 'call',\n",
       " 'cast',\n",
       " 'charact',\n",
       " 'come',\n",
       " 'comedi',\n",
       " 'complet',\n",
       " 'could',\n",
       " 'cours',\n",
       " 'day',\n",
       " 'differ',\n",
       " 'direct',\n",
       " 'director',\n",
       " 'done',\n",
       " 'dvd',\n",
       " 'effect',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'entertain',\n",
       " 'episod',\n",
       " 'especi',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'everyth',\n",
       " 'expect',\n",
       " 'fact',\n",
       " 'famili',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'feel',\n",
       " 'film',\n",
       " 'final',\n",
       " 'find',\n",
       " 'first',\n",
       " 'found',\n",
       " 'friend',\n",
       " 'fun',\n",
       " 'funni',\n",
       " 'get',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'go',\n",
       " 'goe',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'guy',\n",
       " 'happen',\n",
       " 'hard',\n",
       " 'help',\n",
       " 'hope',\n",
       " 'horror',\n",
       " 'howev',\n",
       " 'idea',\n",
       " 'interest',\n",
       " 'job',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'last',\n",
       " 'laugh',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'let',\n",
       " 'life',\n",
       " 'like',\n",
       " 'line',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'made',\n",
       " 'make',\n",
       " 'man',\n",
       " 'mani',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'mean',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'minut',\n",
       " 'moment',\n",
       " 'move',\n",
       " 'movi',\n",
       " 'much',\n",
       " 'music',\n",
       " 'must',\n",
       " 'name',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'noth',\n",
       " 'old',\n",
       " 'one',\n",
       " 'origin',\n",
       " 'part',\n",
       " 'peopl',\n",
       " 'perform',\n",
       " 'person',\n",
       " 'place',\n",
       " 'play',\n",
       " 'plot',\n",
       " 'point',\n",
       " 'pretti',\n",
       " 'probabl',\n",
       " 'put',\n",
       " 'quit',\n",
       " 'rather',\n",
       " 'read',\n",
       " 'real',\n",
       " 'realli',\n",
       " 'reason',\n",
       " 'recommend',\n",
       " 'right',\n",
       " 'role',\n",
       " 'run',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'scene',\n",
       " 'screen',\n",
       " 'script',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seen',\n",
       " 'sens',\n",
       " 'seri',\n",
       " 'set',\n",
       " 'shot',\n",
       " 'show',\n",
       " 'sinc',\n",
       " 'someth',\n",
       " 'star',\n",
       " 'start',\n",
       " 'still',\n",
       " 'stori',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'tell',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'time',\n",
       " 'tri',\n",
       " 'turn',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'us',\n",
       " 'use',\n",
       " 'want',\n",
       " 'war',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'well',\n",
       " 'whole',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'wonder',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'year',\n",
       " 'yet',\n",
       " 'young']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features extraídas\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um dataframe com as features extraídas \n",
    "df_modelo = pd.DataFrame(X.toarray(),\n",
    "                    columns = vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterei os valores de \"sentiment\" para inteiros para aplicar o modelo\n",
    "df_Y = df[\"sentiment\"]\n",
    "df_Y = df_Y.str.replace(\"positive\",\"1\")\n",
    "df_Y = df_Y.str.replace(\"negative\",\"0\")\n",
    "df_Y = df_Y.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 -) Aplicando um modelo\n",
    "Para aplicar um modelo, vamos dividir o dataset em treino e teste e depois aplicarmos alguns classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports para aplicação do nosso modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports para avaliar o modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar o nosso dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_modelo, df_Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando o modelo\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>almost</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>alway</th>\n",
       "      <th>american</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>wonder</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38094</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40624</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49425</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       act  action  actor  actual  almost  also  although  alway  american  \\\n",
       "38094    0       0      0       0       0     0         0      0         0   \n",
       "40624    0       0      0       0       0     0         0      0         0   \n",
       "49425    1       0      0       1       0     1         0      0         0   \n",
       "35734    0       0      0       0       0     0         0      0         0   \n",
       "41708    0       2      0       0       0     0         0      0         0   \n",
       "\n",
       "       anoth  ...  woman  wonder  work  world  worst  worth  would  year  yet  \\\n",
       "38094      2  ...      0       0     0      0      0      0      0     0    0   \n",
       "40624      0  ...      0       0     0      0      0      0      1     1    0   \n",
       "49425      0  ...      0       0     0      0      0      0      0     0    1   \n",
       "35734      0  ...      0       0     0      0      0      0      0     0    0   \n",
       "41708      0  ...      0       0     0      0      0      0      1     0    0   \n",
       "\n",
       "       young  \n",
       "38094      0  \n",
       "40624      0  \n",
       "49425      0  \n",
       "35734      0  \n",
       "41708      0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitando o modelo com os dados de treino\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculando a acurácia do modelo de árvore de decisão\n",
    "ACC = accuracy_score(y_test, y_pred)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4965 2446]\n",
      " [2534 5055]]\n"
     ]
    }
   ],
   "source": [
    "#matriz de confusão\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67      7411\n",
      "           1       0.67      0.67      0.67      7589\n",
      "\n",
      "    accuracy                           0.67     15000\n",
      "   macro avg       0.67      0.67      0.67     15000\n",
      "weighted avg       0.67      0.67      0.67     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#outras métricas incluindo o f1\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intsanciando e fitando o modelo com a base de treino\n",
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculando a acurácia do modelo de regressão logística\n",
    "ACC2 = accuracy_score(y_test, y_pred2)\n",
    "ACC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5730 1681]\n",
      " [1484 6105]]\n"
     ]
    }
   ],
   "source": [
    "#matriz de confusão\n",
    "print(confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      7411\n",
      "           1       0.78      0.80      0.79      7589\n",
      "\n",
      "    accuracy                           0.79     15000\n",
      "   macro avg       0.79      0.79      0.79     15000\n",
      "weighted avg       0.79      0.79      0.79     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#outras métricas incluindo o f1\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando o modelo\n",
    "rfc = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitando o modelo com a base de treino\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7750666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculando a acurácia do modelo\n",
    "ACC3 = accuracy_score(y_test, y_pred3)\n",
    "ACC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5629 1782]\n",
      " [1592 5997]]\n"
     ]
    }
   ],
   "source": [
    "#matriz de confusão\n",
    "print(confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      7411\n",
      "           1       0.77      0.79      0.78      7589\n",
      "\n",
      "    accuracy                           0.78     15000\n",
      "   macro avg       0.78      0.77      0.77     15000\n",
      "weighted avg       0.78      0.78      0.77     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#outras métricas incluindo o f1\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão \n",
    "Para o nosso modelo, vimos que dentre os 3, o com a melhor performance foi o modelo de Regressão Logística. Vale ressaltar que foi a aplicação de um modelo bem simples, sem uma otimização de hiperparâmetros e de outros parâmetros como a quantidade máxima de features do CountVectorizer por exemplo. Sobre as performances no geral, podemos ver que o modelo de Regressão Logística ficou bem próximo do de Florestas Aleatórias enquanto que houve um resultado já bem abaixo por parte do modelo de Árvore de Decisão. Sobre as métricas individuais, obtivemos uma matriz de confusão boa nos 2 últimos modelos com pouca variação de resultado tanto na f1 score (Média harmônica do recall) quanto na precisão do modelo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi uma boa inicialização na área, onde pude me desafiar e aprender bastante com essa aplicação. Continuarei evlouindo para melhores projetos mais para frente. XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
