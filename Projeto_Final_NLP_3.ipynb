{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final do Turing de NLP para os Trainees - Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa última parte do projeto se trata de explorarmos uma outra abordagem: o Word2Vec. Para isso, vamos passar o nosso dataset pré-processado e treinaremos o modelo para depois analisarmos os seus resultados (a partir de métodos como most_similar e doesnt_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports das bibliotecas para o nosso código\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = set(stopwords.words('english')) \n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemos o dataset\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(texto):\n",
    "    soup = BeautifulSoup(texto, \"html.parser\")\n",
    "    texto_tratado = soup.get_text(separator=\" \")\n",
    "    return texto_tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_review(review):\n",
    "    \n",
    "    review_2 = []\n",
    "    for word in review:\n",
    "        word_ = str(word)\n",
    "        word_ = word_.lower() \n",
    "        review_2.append(word_)\n",
    "\n",
    "    return review_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tira_stopwords(review):\n",
    "    \n",
    "    filtered_sentence = [] \n",
    "    for word in review:\n",
    "        if word not in stop_words: \n",
    "            filtered_sentence.append(word) \n",
    "            \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#igual a função da parte 1 de pré-processamento\n",
    "def pre_processamentos(review):\n",
    "    #primeiro vamos retirar as tags de html\n",
    "    review = strip_html_tags(review)\n",
    "    \n",
    "    #selecionamos as palavras sem os números\n",
    "    review = re.findall(r'[a-z,A-Z]\\w+',review)\n",
    "    \n",
    "    #das palavras vamos retirar os espaços\n",
    "    review = trata_review(review)\n",
    "    \n",
    "    #agora vamos tirar os stopwords\n",
    "    review = tira_stopwords(review)\n",
    "    \n",
    "    #Stemização das palavras   \n",
    "    for i in range(len(review)):\n",
    "        review[i] = porter.stem(review[i])\n",
    "                                          \n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos o pré-processamento\n",
    "df[\"review_tratado\"] = df[\"review\"].apply(lambda x: pre_processamentos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#para facilitar a referenciação\n",
    "texto = df[\"review_tratado\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectar bigramas\n",
    "Vamos passar o nosso texto para identificar bigramas e coloquei que a palavra precisa aparecer pelo menos 20 vezes para ser considerada um bigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(texto, min_count=2, threshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos com o nosso modelo já detectando bigramas e depois de já ver alguns que ele identificou, mostrarei como que ele reconhece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'is', 'a', 'spoiler_alert']\n"
     ]
    }
   ],
   "source": [
    "print(bigram['there is a spoiler alert'.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that', 'film', 'has', 'an', 'incredible', 'special_effect']\n"
     ]
    }
   ],
   "source": [
    "print(bigram['that film has an incredible special effect'.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando o bigrama para todo o nosso texto\n",
    "sentences = bigram[texto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports das bibliotecas\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para treinar o nosso modelo, precisamos passar alguns parâmetros:\n",
    "* size = dimensionalidade dos word vectors\n",
    "* sg = o algoritmo de treino\n",
    "* min_count = ignora todas as palavras com frequência total menores que esse valor\n",
    "* window = distância da palavra atual e da que queremos prever dentro de uma sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(min_count = 3, size = 100, window = 2, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construção da tabela de vocabulário\n",
    "w2v.build_vocab(sentences) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o modelo preparado e a tabela de vocabulário construída, podemos treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75846426, 81930105)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(sentences, total_examples = w2v.corpus_count, epochs = 15, report_delay = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do resultado \n",
    "Para analisarmos o resultado, vamos utilizar os seguintes métodos:\n",
    "* most_similar\n",
    "* similarity\n",
    "* doesnt_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_similar\n",
    "Para esse método, podemos passar tanto \"positive\" como \"negative\" e pode ser um conjunto de palavras ao invés de uma só. Como retorno, recebemos as palvras mais ou menos próximas em relação a palavra(s) passada(s) como parâmetro(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 0.905087947845459),\n",
       " ('tear_kali', 0.7367988228797913),\n",
       " ('inglouri_basterd', 0.7319300174713135),\n",
       " ('rescu_dawn', 0.7277275323867798),\n",
       " ('gujarati_theatr', 0.7251120209693909),\n",
       " ('irreproach', 0.723563551902771),\n",
       " ('casual_observ', 0.7228260040283203),\n",
       " ('strayer', 0.7208144664764404),\n",
       " ('chill_bone', 0.7205885648727417),\n",
       " ('incoher_narr', 0.7193603515625)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=[\"film\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roy', 0.051863331347703934),\n",
       " ('ra', 0.0025489740073680878),\n",
       " ('proprietor', -0.0045452117919921875),\n",
       " ('maven_recogn', -0.006327278912067413),\n",
       " ('lew', -0.0087735615670681),\n",
       " ('carson', -0.012495450675487518),\n",
       " ('burk', -0.012596890330314636),\n",
       " ('frederick', -0.014837939292192459),\n",
       " ('carolin', -0.01858524978160858),\n",
       " ('lesli', -0.020054414868354797)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(negative=[\"film\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('versatil_actor', 0.6863749623298645),\n",
       " ('anthoni_asquith', 0.6685659885406494),\n",
       " ('second_consecut', 0.6678071022033691),\n",
       " ('john_hickam', 0.6673961877822876),\n",
       " ('michael_sopkiw', 0.6672186851501465),\n",
       " ('estonian', 0.6649237871170044),\n",
       " ('funniest_comedian', 0.6611506938934326),\n",
       " ('miguel_bardem', 0.6584398746490479),\n",
       " ('marg_simpson', 0.6552121043205261),\n",
       " ('hammiest', 0.6488018035888672)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=[\"actor\",\"best\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 0.8408327698707581),\n",
       " ('chill_bone', 0.7950080633163452),\n",
       " ('sean_corinn', 0.7840585112571716),\n",
       " ('recomend_anyon', 0.7738760113716125),\n",
       " ('fiveson', 0.7710902690887451),\n",
       " ('adventur_hercul', 0.7694024443626404),\n",
       " ('squirm_induc', 0.7652233839035034),\n",
       " ('fiendishli', 0.764042854309082),\n",
       " ('senc', 0.7617179751396179),\n",
       " ('especiali', 0.7566429972648621)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=[\"good\",\"film\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity\n",
    "Com esse método podemos ver o quão similar são duas palavras. Ela retorna o valor da similaridade entre elas como porcentagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44544148"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"good\",\"film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3484704"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"good\",\"actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7305117"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"actress\",\"actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69358337"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7184862"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"great\",\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42829686"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"film\",\"that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3484704"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(\"actor\",\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que palavras com características semelhantes apresentam uma maior similaridade e que, como esperado, a ordem em que as palavras são passadas não afeta no resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doesnt_match\n",
    "Esse método podemos passar uma lista de palavras e o modelo vai tentar acertar qual palavra que não tem relação com a lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojimisumi/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.doesnt_match([\"actor\",\"good\",\"actress\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actress'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.doesnt_match([\"perfect\",\"good\",\"actress\",\"great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actor'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.doesnt_match([\"action\",\"comedy\",\"drama\",\"romance\",\"actor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelos exemplos acima, vemos que o modelo conseguiu acertar na palavra que não pertencia a lista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "Essa foi a última parte do Projeto Final de NLP para os Trainees. Foi muito interessanta ver como o modelo tenta pegar o contexto tanto para achar bigramas como para análise do modelo (como por exemplo \"similarity\" e \"doesnt_match\")para ter uma análise um pouco mais profunda sobre o texto (no caso, os reviews) ao invés de pegarem puramente as palavras separadamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gostei muito de terminar esse projeto! Foi muito desafiador e estou ansioso pelos próximos que virão!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
